{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#in the future, use abbreviations for the column variables names\n",
    "\n",
    "#globals\n",
    "datasetNum = 1\n",
    "\n",
    "# load the dataset\n",
    "testPath = '/Users/shreejakikkisetti/Desktop/CMaps/test_FD00' + str(datasetNum) + '.txt'\n",
    "testdf = pd.read_csv(testPath, ' ', header=None)\n",
    "trainPath = '/Users/shreejakikkisetti/Desktop/CMaps/train_FD00' + str(datasetNum) + '.txt'\n",
    "traindf = pd.read_csv(trainPath, ' ', header=None)\n",
    "RULPath = '/Users/shreejakikkisetti/Desktop/CMaps/RUL_FD00' + str(datasetNum) + '.txt'\n",
    "TestUnitToRUL = pd.read_csv(RULPath, header=None)[0].tolist()\n",
    "\n",
    "#reformat + add headers\n",
    "testdf = testdf.loc[:,0:25]\n",
    "traindf = traindf.loc[:,0:25]\n",
    "colNames = ['unit #', 'time (cycles)', 'operational setting 1', 'operational setting 2', 'operational setting 3']\n",
    "for i in range(1,22):\n",
    "    colNames.append('sensor measurement ' + str(i))\n",
    "testdf.columns = colNames\n",
    "traindf.columns = colNames\n",
    "TestUnitToRUL.insert(0,'NaN') #to make indices match unit #s\n",
    "#TestRULdf.insert(loc=0,column=1,value=list(range(0,TestRULdf.shape[0])))\n",
    "#TestRULdf.columns = ['unit #', 'Actual RUL']\n",
    "#print(traindf.shape)    \n",
    "#print(TestRULdf) \n",
    "#print(traindf)\n",
    "\n",
    "#calculate TrainUnittoTotalLife\n",
    "TrainUnittoTotalLife = ['NaN']#first value not defined t omake indices match unit #s\n",
    "for i in range(traindf['unit #'].min(),traindf['unit #'].max()+1):\n",
    "    TrainUnittoTotalLife.append(traindf[traindf['unit #'] == i]['time (cycles)'].max()) #first part extracts rows that meet the given condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Population plots on training data\n",
    "\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "#compute average values for each parameter for each time interval\n",
    "#not enough values at high values of t --> lots of noise\n",
    "timeAvgs = [None]*24#24 dimensions that vary by time\n",
    "counts = [None]*24\n",
    "for i in range(0,24):\n",
    "    timeAvgs[i] = [0]*(max(traindf['time (cycles)']))\n",
    "    counts[i] = [0]*(max(traindf['time (cycles)']))\n",
    "for i in range(0,24):\n",
    "    for j in range(0,traindf.shape[0]):\n",
    "        timeAvgs[i][traindf['time (cycles)'][j]-1] += traindf[colNames[i+2]][j]\n",
    "        counts[i][traindf['time (cycles)'][j]-1] += 1\n",
    "for i in range(0,24):\n",
    "    for j in range(0,max(traindf['time (cycles)'])):\n",
    "        timeAvgs[i][j] /= counts[i][j]#counts has to be above 0\n",
    "        \n",
    "timeAvgsdf = pd.DataFrame(data=timeAvgs).T\n",
    "timeAvgsdf.columns = colNames[2:]\n",
    "\n",
    "\n",
    "#plot\n",
    "\n",
    "for i in range(1,4):\n",
    "    subPlt = traindf.plot.scatter(title = 'Population Data OS' + str(i) + ' vs. Time for FD001', x='time (cycles)', y='operational setting ' + str(i), s=0.1, alpha=0.5)\n",
    "    s = UnivariateSpline(list(range(1,max(traindf['time (cycles)']+1))), timeAvgsdf['operational setting ' + str(i)].tolist())\n",
    "    xs = np.linspace(0, max(traindf['time (cycles)']), 100)\n",
    "    ys = s(xs)\n",
    "    subPlt.plot(xs,ys,color='r')\n",
    "    #print(timeAvgsdf['operational setting ' + str(i)])\n",
    "for i in range(1,22):\n",
    "    subPlt = traindf.plot.scatter(title = 'Population Data SM' + str(i) + ' vs. Time for FD001', x='time (cycles)', y='sensor measurement ' + str(i), s=0.1, alpha=0.5)\n",
    "    #subPlt.plot(list(range(1,max(traindf['time (cycles)'])+1)),timeAvgsdf['sensor measurement ' + str(i)])\n",
    "    s = UnivariateSpline(list(range(1,max(traindf['time (cycles)']+1))), timeAvgsdf['sensor measurement ' + str(i)].tolist())\n",
    "    xs = np.linspace(0, max(traindf['time (cycles)']), 100)\n",
    "    ys = s(xs)\n",
    "    subPlt.plot(xs,ys,color='r')\n",
    "    \n",
    "    \n",
    "#need to review vectorization for faster processing (and less code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data pre-processing\n",
    "#not tested for logic errors\n",
    "\n",
    "import random\n",
    "\n",
    "#remove constants\n",
    "constVar = ['operational setting 3', 'sensor measurement 1', 'sensor measurement 5', 'sensor measurement 10',\n",
    "            'sensor measurement 16', 'sensor measurement 18', 'sensor measurement 19']\n",
    "#for var in constVar:\n",
    "#    testdf = testdf.drop([var],axis=1)\n",
    "#    traindf = traindf.drop([var],axis=1)\n",
    "    \n",
    "first = True\n",
    "#calculate training data\n",
    "trainData = []\n",
    "trainRUL = []\n",
    "for i in range(traindf['unit #'].min(),traindf['unit #'].max()+1): \n",
    "    totTime = TrainUnittoTotalLife[i] #total time until system failure\n",
    "    for j in range(0,5):#5 samples for each training unit\n",
    "        entry = []\n",
    "        endTime = random.randint(1,totTime)  #end time for input data on this engine; random inclusive on both sides\n",
    "        entry.append(endTime)\n",
    "        entry = entry + traindf[(traindf['unit #'] == i) & (traindf['time (cycles)'] == 1)].values.tolist()[0][2:]\n",
    "        entry = entry + traindf[(traindf['unit #'] == i) & (traindf['time (cycles)'] == int(endTime/2+1))].values.tolist()[0][2:]\n",
    "        entry = entry + traindf[(traindf['unit #'] == i) & (traindf['time (cycles)'] == endTime)].values.tolist()[0][2:] \n",
    "        trainData.append(entry)\n",
    "        trainRUL.append(totTime - endTime)\n",
    "        first = False\n",
    "testData = []\n",
    "testRUL = []\n",
    "for i in range(testdf['unit #'].min(),testdf['unit #'].max()+1): \n",
    "    entry = []\n",
    "    endTime = testdf[testdf['unit #'] == i]['time (cycles)'].max()\n",
    "    entry.append(endTime)\n",
    "    entry = entry + testdf[(testdf['unit #'] == i) & (testdf['time (cycles)'] == 1)].values.tolist()[0][2:]\n",
    "    entry = entry + testdf[(testdf['unit #'] == i) & (testdf['time (cycles)'] == int(endTime/2+1))].values.tolist()[0][2:]\n",
    "    entry = entry + testdf[(testdf['unit #'] == i) & (testdf['time (cycles)'] == endTime)].values.tolist()[0][2:]\n",
    "    testData.append(entry)\n",
    "    testRUL.append(TestUnitToRUL[i])\n",
    "\n",
    "#print(trainData[0])\n",
    "#print(trainRUL[0])\n",
    "#print(testData[0])\n",
    "#print(testRUL[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN\n",
    "\n",
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import datetime\n",
    "\n",
    "#create model\n",
    "model = keras.Sequential()\n",
    "n_features = len(trainData[0]) #number of input features\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))#kernel_initializer = layer weight initializer (what type should I use?)\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1))#one output\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])#optimizer controls learning rate\n",
    "\n",
    "#train model\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model.fit(trainData, trainRUL, epochs=10, batch_size=32, verbose=2, callbacks=[tensorboard_callback])\n",
    "%tensorboard --logdir logs/fit\n",
    "\n",
    "#evaluate model\n",
    "loss, mse = model.evaluate(testData, testRUL, verbose=0)#what's loss vs. accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#https://www.tensorflow.org/tensorboard/get_started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
